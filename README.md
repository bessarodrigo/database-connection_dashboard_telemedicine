# Integra√ß√£o de Dados e Visualiza√ß√£o - Empresa de Telemedicina

## Vis√£o Geral
Projeto que tem como objetivo **automatizar o processo de ingest√£o e visualiza√ß√£o de dados** para uma opera√ß√£o de uma empresa de telemedicina (considerando os dados de produtos e da √°rea financeira), utilizando ferramentas de ETL, armazenamento e visualiza√ß√£o. A arquitetura √© escal√°vel, documentada e organizada para fins de portf√≥lio profissional.

## Arquitetura 

### Fonte dos Dados
- planilhas Excel com m√∫ltiplas abas

### ETL com Python
- Leitura e tratamento dos dados usando pandas
- Convers√£o e padroniza√ß√£o de colunas (`DATE`, `FLOAT`, `STRING`)
- Estrutura modular com fun√ß√£o upload_to_bigquery_from_excel reutiliz√°vel
- Uso de `.env` para vari√°veis de ambiente

### Carga no Banco de Dados
- **PostgreSQL:** utilizado como banco relacional local em fase inicial
- **Google BigQuery:** usado como armazenamento em nuvem final, estruturado por datasets: seguros, financeiro, saude
-  Carga usando API oficial do BigQuery com `LoadJobConfig`

### Visualiza√ß√£o
- Conex√£o direta do BigQuery com o Looker Studio

## Estrutura do Projeto
```text
üìÅ projeto/
‚îú‚îÄ‚îÄ üìÅ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ bq_connection_nomedatabela.ipynb
‚îú‚îÄ‚îÄ üìÅ credenciais/
‚îÇ   ‚îî‚îÄ‚îÄ bq-chave.json
‚îú‚îÄ‚îÄ üìÅ dados/
‚îÇ   ‚îî‚îÄ‚îÄ relatorio_consolidado.xlsx
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Tecnologias Utilizadas
| Ferramenta                  | Papel                              |
| --------------------------- | ---------------------------------- |
| **Python (pandas, dotenv)** | ETL, tratamento e envio dos dados  |
| **PostgreSQL**              | Banco relacional local             |
| **Google BigQuery**         | Armazenamento anal√≠tico e consulta |
| **Looker Studio**           | Pain√©is e visualiza√ß√£o             |
| **Jupyter Notebook**        | Desenvolvimento interativo         |
| **GitHub**                  | Controle de vers√£o e documenta√ß√£o  |

## Exemplos
---

### Envio de DataFrames para BigQuery

```python
def upload_to_bigquery_from_excel(sheet_name: str, table_name: str, schema: list):
    excel_path = os.getenv("EXCEL_FILE_PATH")
    if not excel_path or not os.path.exists(excel_path):
        raise FileNotFoundError("Arquivo Excel n√£o encontrado ou vari√°vel EXCEL_FILE_PATH n√£o definida.")
        
    df = pd.read_excel(excel_path, sheet_name=sheet_name)

    # Convers√£o de colunas do tipo DATE
    date_columns = [field.name for field in schema if field.field_type == "DATE"]
    for col in date_columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')

    job_config = bigquery.LoadJobConfig(
        schema=schema,
        write_disposition="WRITE_TRUNCATE"
    )

    full_table_id = f"{project_id}.{dataset_id}.{table_name}"
    job = client.load_table_from_dataframe(df, full_table_id, job_config=job_config)
    job.result()

    print(f"‚úÖ Dados enviados com sucesso para: {full_table_id}")

### Exemplo de Uso da Fun√ß√£o
```python
schema_meta_odonto = [
    bigquery.SchemaField("Mes", "DATE"),
    bigquery.SchemaField("Meta", "INTEGER"),
]

upload_to_bigquery_from_excel(
    sheet_name='meta_odonto',
    table_name='meta_odonto',
    schema=schema_meta_odonto
)
